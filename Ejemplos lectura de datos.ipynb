{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1198b22b-6d05-410a-95b8-570c7b523bdf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Vamos a usar un fichero de ejemplo que ya está almacenado en databricks. Podriamos subir otro fichero si lo deseamos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a151cfa-6214-494f-b380-1ea8cb416e2e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\") \\\n",
    "  .option(\"inferSchema\", \"false\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .load(\"/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28e49271-abd7-4549-b5ad-f69f6085382e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Al usar la opcion `.option(\"inferSchema\", \"false\")`, no intentara inferir el schema y todas las columnas son leidas como Strings\n",
    "\n",
    "Todas las opciones para el formato `csv`: https://spark.apache.org/docs/latest/sql-data-sources-csv.html#data-source-option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a18d10b1-390c-4f8b-ba2c-fdb1784abeee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59bbb052-f157-4b02-8933-5e5393492cd6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Si se lo indicamos spark intentará inferir los tipos.\n",
    "\n",
    "Veamos que tal funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75c54ae7-a398-46d6-bce1-f3f13c4d1a7e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_infered_types = spark.read.format(\"csv\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .load(\"/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv\")\n",
    "\n",
    "df_infered_types.printSchema()\n",
    "\n",
    "display(df_infered_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53db402b-3701-4a4c-ae65-92df3088e3e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Lo ha hecho bastante bien, ha identificado correctamente 'Call Date' y 'Watch Date' como fechas pero no ha podido identificar 'Available DtTm' como timestamp (fecha+hora)\n",
    "\n",
    "La inferencia de tipos es muy útil pero en muchas ocasiones necesitaremos especificar el esquema para un correcto parseo de los datos. Siempre será más interesante hacerlo ya en la carga que implementar transformaciones a posteriori.\n",
    "\n",
    "Como hacerlo? Existen dos opciones para espcificar esquemas en Spark:\n",
    "\n",
    "* Usando StructType \n",
    "* Usando DDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a0ffc87-4424-4a4c-bfb0-e102f9998444",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, TimestampType, IntegerType, BooleanType, DoubleType\n",
    "\n",
    "valid_schema = StructType(\n",
    "    [\n",
    "        StructField('Call Number', IntegerType(), True), \n",
    "        StructField('Unit ID', StringType(), True), \n",
    "        StructField('Incident Number', IntegerType(), True), \n",
    "        StructField('CallType', StringType(), True), \n",
    "        StructField('Call Date', DateType(), True), \n",
    "        StructField('Watch Date', DateType(), True), \n",
    "        StructField('Call Final Disposition', StringType(), True), \n",
    "        StructField('Available DtTm', TimestampType(), True),\n",
    "        StructField('Address', StringType(), True), \n",
    "        StructField('City', StringType(), True), \n",
    "        StructField('Zipcode of Incident', IntegerType(), True), \n",
    "        StructField('Battalion', StringType(), True), \n",
    "        StructField('Station Area', StringType(), True), \n",
    "        StructField('Box', StringType(), True), \n",
    "        StructField('OrigPriority', StringType(), True), \n",
    "        StructField('Priority', StringType(), True), \n",
    "        StructField('Final Priority', IntegerType(), True), \n",
    "        StructField('ALS Unit', BooleanType(), True), \n",
    "        StructField('Call Type Group', StringType(), True), \n",
    "        StructField('NumAlarms', IntegerType(), True), \n",
    "        StructField('UnitType', StringType(), True), \n",
    "        StructField('Unit sequence in call dispatch', IntegerType(), True), \n",
    "        StructField('Fire Prevention District', StringType(), True), \n",
    "        StructField('Supervisor District', StringType(), True), \n",
    "        StructField('Neighborhood', StringType(), True), \n",
    "        StructField('Location', StringType(), True), \n",
    "        StructField('RowID', StringType(), True), \n",
    "        StructField('Delay', DoubleType(), True)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "df_explicit_types_using_structtype = spark.read.format(\"csv\") \\\n",
    "  .option(\"inferSchema\", \"false\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .schema(valid_schema) \\\n",
    "  .load(\"/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv\")\n",
    "\n",
    "df_explicit_types_using_structtype.printSchema()\n",
    "\n",
    "display(df_explicit_types_using_structtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77a8c204-07aa-458a-8cc8-0c2681b49b5c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Hay un problema, no ha sido capaz de parsear correctamente las fechas.\n",
    "\n",
    "Se debe a que el formato de la fecha es el formato por defecto, debemos especifirlo con `.option(\"dateFormat\", \"dd/MM/yyyy\")` y lo mismo sucede con el timestamp, ejemplo: `01/11/2002 01:51:54 AM`, patron correspondiente `MM/dd/yyyy hh:mm:ss a`\n",
    "\n",
    "Como definr los patrones: https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "291bcf87-30db-4753-a5b6-ddbd5e3917b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_explicit_types_using_structtype = spark.read.format(\"csv\") \\\n",
    "  .option(\"inferSchema\", \"false\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .option(\"dateFormat\", \"MM/dd/yyyy\") \\\n",
    "  .option(\"timestampFormat\", \"MM/dd/yyyy hh:mm:ss a\") \\\n",
    "  .schema(valid_schema) \\\n",
    "  .load(\"/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv\")\n",
    "\n",
    "df_explicit_types_using_structtype.printSchema()\n",
    "\n",
    "display(df_explicit_types_using_structtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf835a5c-6a79-4930-9c8f-b4583524ee7a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Tambien se puede definir el esquema con DLL, misma sintaxis que usariamos en un CREATE TABLE. Un string con los nombres de las columnas y su tipo separados por coma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "027876fe-ef7b-4349-8f85-d465b3246436",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_schema_ddl = \"\"\"Call_Number INTEGER,\n",
    "    Unit_ID STRING,\n",
    "    Incident_Number INTEGER,\n",
    "    CallType STRING,\n",
    "    Call_Date DATE,\n",
    "    Watch_Date DATE,\n",
    "    Call_Final_Disposition STRING,\n",
    "    Available_DtTm TIMESTAMP,\n",
    "    Address STRING,\n",
    "    City STRING,\n",
    "    Zipcode_of_Incident INTEGER,\n",
    "    Battalion STRING,\n",
    "    Station_Area STRING,\n",
    "    Box STRING,\n",
    "    OrigPriority STRING,\n",
    "    Priority STRING,\n",
    "    Final_Priority INTEGER,\n",
    "    ALS_Unit BOOLEAN,\n",
    "    Call_Type_Group STRING,\n",
    "    NumAlarms INTEGER,\n",
    "    UnitType STRING,\n",
    "    Unit_sequence_in_call_dispatch INTEGER,\n",
    "    Fire_Prevention_District STRING,\n",
    "    Supervisor_District STRING,\n",
    "    Neighborhood STRING,\n",
    "    Location STRING,\n",
    "    RowID STRING,\n",
    "    Delay DOUBLE\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd8643b6-9aa2-4047-b1bc-70565eb85c4f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Modos de lectura\n",
    "\n",
    "Probemos los distintos modos dorzando un error al no espcificar los patrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e801994-ad5b-4c32-a06b-034586f9c625",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_failfast = spark.read.format(\"csv\") \\\n",
    "  .option(\"inferSchema\", \"false\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .option(\"mode\", \"FAILFAST\") \\\n",
    "  .schema(valid_schema_ddl) \\\n",
    "  .load(\"/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv\")\n",
    "\n",
    "display(df_failfast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2b9e7fe-0003-4fea-bd50-c057eeecc930",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_permissive = spark.read.format(\"csv\") \\\n",
    "  .option(\"inferSchema\", \"false\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .option(\"mode\", \"PERMISSIVE\") \\\n",
    "  .schema(valid_schema_ddl) \\\n",
    "  .load(\"/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv\")\n",
    "\n",
    "display(df_permissive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b54c72c-bfbe-4c29-8d59-694f8dbbfd5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_dropmalformed = spark.read.format(\"csv\") \\\n",
    "  .option(\"inferSchema\", \"false\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "  .schema(valid_schema_ddl) \\\n",
    "  .load(\"/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv\")\n",
    "\n",
    "display(df_dropmalformed)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Ejemplos lectura de datos",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
